= Blue Whales on ECStasy
https://github.com/les
2017-09-19
:copyright: CC BY-SA 4.0
:figure-caption!:
:backend: revealjs
:revealjs_theme: simple
:revealjs_controls: false
:revealjs_progress: false
:revealjs_slideNumber: 'c/t'
:revealjs_history: true
:revealjs_transition: none
:revealjs_transitionSpeed: fast
:revealjs_backgroundTransition: none
:revealjs_width: '100%'
:revealjs_height: '100%'
:revealjs_margin: 0.1
:revealjs_minScale: 0.2
:revealjs_maxScale: 1.5
:source-highlighter: highlightjs
:highlightjs-theme: reveal.js/lib/css/grayscale.css
:customcss: README/custom.css


== Disclaimer

In the interests of time, this talk will be quite high-level and does not aim to teach you everything you need to know about Amazon ECS; however, it assumes at least a basic knowledge of AWS and Docker.

https://github.com/les/bluewhales[This document] (https://les.github.io/bluewhales/[and resulting slide deck]) is intentionally dense, so you (and others) can use it for future reference.

Kate Libby (a.k.a Acid Burn) considers me `31337`; however, I don't work for Amazon and things change, so please do your own research and make your decisions.


== !

THE DOCUMENT IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE INFORMATION CONTAINED WITHIN.


== Aim

What if I said, I could help reduce your AWS spend by up to 75%?^*^

[.smallprint]
^*^Average figure based on several simulated test cases, your mileage my vary.


== But before we get into that, let's tackle the small issue of the title.


== What are blue whales?

* Up to 98ft (30m) in length and with a maximum recorded weight of 173t (173,000kg), the blue whale (Balaenoptera musculus) is the largest animal known to have ever existed.
* A blue whale's tongue weighs as much as an elephant and their heart is 640x heavier than ours.
* A blue whale's call is louder than a jumbo jet (at take-off) and can be heard from over 500mi (805km) away.
* Blue whales eat an elephant every day, but they can only swallow a grapefruit.
* A blue whale's age can be determined by its earwax.
* The average lifespan of a blue whale is 80-90 years, but the oldest one recorded (based on it's earwax) was ~110yo.

[NOTE.speaker]
--
Gravity limits the size of land animals to what their skeletons can support.
The African elephant (Loxodonta), is the largest/heaviest land animal; males stand up to 13ft (4.0m) tall at the shoulder and can weigh up to 6t (6,000kg).

Land animals need to use their skeleton and muscles to support their body mass against the force of gravity (an elephant's skeleton comprises 27% of its body weight), whereas marine mammals are supported by the buoyant force of salt water (a blue whale's skeleton only comprises 15% of its body weight).

Sadly, if you were to remove a blue whale from the ocean it would be crushed to death under its own weight a result of the effects of gravity.

A blue whale's heart weighs about 640 times as much as a human heart.

Blue whales have one of the loudest calls in the animal kingdom, measuring up to 188dB, their song is louder than a jumbo jet at take-off (140dB) .

For 8 months of the year, blue whales eat virtually nothing, but during the summer months they feed almost continuously, scooping up 4-8t (4,000-8,000kg) of krill every day.

A blue whale's throat is almost exactly the same diameter as its belly button (roughly the size of a side plate), but a little smaller than its eardrum (roughly the size of a dinner plate).

About every 6 months a new layer of wax forms inside a whale's ear canal.
The wax primarily services to protect the ear canal and counterintuitively helps carry sound waves into the whale's inner ear.
This build up of wax layers, called an earplug, can be measured and used to estimate a whale's age, much like counting the rings in a tree trunk.
--


== What is ecstasy?

* 3,4-Methylenedioxymethamphetamine (MDMA), commonly referred to as ecstasy or E, is a psychoactive compound used primarily as a recreational drug.
* Desired effects include increased empathy, euphoria, and heightened sensations.
* Adverse effects include addiction, memory problems, paranoia, difficulty sleeping, teeth grinding, blurred vision, sweating and a rapid heartbeat.
* Effects begin 30-45 minutes after ingestion and last 3-6 hours.
* Street ecstasy (pill form) is usually coloured and stamped with different logos (e.g. Macintosh, 007, Superman, Playboy, Mitsubishi, Rolls Royce, etc.).
* As of 2017, MDMA has no accepted medical uses.


== "That's great, but what's all this got to do with a Docker Meetup?"


== !

.Courtesy of https://www.docker.com/[Docker, Inc.]
image::README/moby-dock.svg[Moby Dock]

Docker's logo is a blue whale named Moby Dock, hence the https://github.com/moby[Moby Project].

[NOTE.speaker]
--
Docker, Inc. (the company) decided to differentiate Docker's commercial software products (Docker Community Edition, Docker Enterprise Edition, Docker Cloud, etc.) from the free (https://www.gnu.org/philosophy/free-sw.en.html[as in freedom]) Docker source code by renaming it to the https://mobyproject.org/[Moby Project].
--


== !

.Courtesy of https://blog.docker.com/2015/02/docker-project-announces-open-source-a-thon-to-support-whale-and-marine-wildlife-conservation/[Docker, Inc.]
image::README/molly-dock.jpg[Molly Dock]

In February 2015 as part of their 2nd birthday celebrations, Docker donated $25,000 to the http://www.oceanicsociety.org/[Oceanic Society, California] to adopt a female blue whale (#763), which they named Molly Dock^*^.

[.smallprint]
^*^Thankfully, Docker employees have no official responsibilities in taking care of the whale.

[NOTE.speaker]
--
#763 was named Molly Dock, so that the blue whale in Docker's logo, named Moby Dock, would have a female companion.

Roderic Mast, president of the Oceanic Society, also organised a whale watching trip with Docker employees; although, there's no evidence to suggest any of them have every actually seen Molly Dock.
--


== "So that's the blue whales, what about the ecstasy?"


== Well, like ECStasy, Amazon EC2 Container Service (Amazon ECS) will make you (and your boss) very happy!


== How?


== By saving you $$$!

[NOTE.speaker]
--
Conveniently E, C and S are also the first three letters making up the word ecstasy.
--


== What is Docker?

You can think of Docker as chroot(1) on steroids^*^.

[.smallprint]
^*^YADR (Yet Another Drug Reference), this time used by Klaus Schmidt to describe Solaris Containers Zones in his book High Availability and Disaster Recovery: Concepts, Design, Implementation (Springer-Verlag, 2006).

[NOTE.speaker]
--
Chroot is an operation that changes the apparent root directory of a running process to isolate it and its children from the rest of the system; thus a chrooted program cannot access files and commands outside of it's directory tree.
This modified environment is called a chroot jail (which is likely where you will go if buy/sell drugs).
They can only be used for processes that do not run as root, since root users can easily break out of a chroot jail by chrooting back to `/`.
--


== !

.Courtesy of http://dockerdocs.org/what-is-docker/[Docker Docs]
image::README/vm-vs-c8.png[Virtual Machines vs. Containers,,800]

[NOTE.speaker]
--
You all should recognise this, but for those of you who don't.
--


== What is ECS?

Before we look at ECS we need to explore a few other things first, like how Amazon makes all of its money though people like you!


== The http://fortune.com/global500[Global 500] ranks Amazon ($135.9B, 2016 FY) the world's 3rd's largest technology company (by revenue) after Samsung ($215.6B, 2016 FY) and Apple ($215.1B, 2016 FY).

[NOTE.speaker]
--
The Fortune Global 500 (a.k.a. the Global 500) is an annual ranking of the top 500 corporations worldwide as measured by revenue.
The list is compiled and published annually by https://en.wikipedia.org/wiki/Fortune_(magazine)[Fortune magazine].

Revenue (a.k.a. turnover), is the income that a business has from its normal business activities (usually from the sale of goods and services to customers) during a given period.
Profit (a.k.a. net income), generally implies total revenue minus total expenses in a given period.
In accounting, revenue is referred to as _"the top line"_, due to its position on the income statement; whereas, profit is referred to a as _"the bottom line"_, which denotes net income (i.e. gross revenues minus total expenses).

A fiscal year (a.k.a. financial year) is the period used by governments for accounting and budget purposes, which vary between countries.
It is also used for financial reporting by business and other organizations.
--


== So, how does Amazon make all this money?

[%step]
* Retail goods?
* Digital content?
* Consumer electronics?
* Jeremy Clarkson, Richard Hammond & James May?
* Over-provisioning on EC2?

[NOTE.speaker]
--
.Retails goods
* Amazon Retail

.Digital content
* Amazon Prime
* Amazon Music
* Amazon Games

.Consumer electronics
* Amazon Kindle
* Amazon Fire
* Amazon Echo/Dot

.Jeremy Clarkson, Richard Hammond & James May
* The Grand Tour

.Over-provisioning on EC2?
* With some help from the microservices trend
--


== Let's quickly talk about microservices

Microservices is an evolution of SOA, whereby large software applications are broken down into a collection of small, modular, loosely-coupled and independently-deployable services that communicates with one another through well-defined, lightweight protocols/APIs.

Decomposing a typically large application into small, functionally-unique microservices, improves modularity and helps makes applications easier to understand, develop, refactor, test and scale (in isolation).


== Microservices have a few drawbacks though...

. Viewing size as the primary structuring mechanism can lead to too many services when the alternative of internal modularisation may result in an overall simpler design.
. Microservices that are too fine-grained are an anti-pattern, i.e. where the overhead outweighs the utility.
. Moving responsibilities between services can be more difficult, i.e. transfer of knowledge between teams, use of multiple programming languages, etc.
. Remote calls (over the network) are more expensive (e.g. network latency, message processing, etc.) than in-process calls.
. Which also introduces additional complexity and new problems, such as network latency, message formats, load balancing and fault tolerance, etc.
. Deployment and integration testing also become more complicated.

[.smallprint]
To mention a few.


== !

[quote, Robert Annett, Where is the complexity? (2014-05-01)]
____
You can move it about but it's still there!
____

[NOTE.speaker]
--
The complexity of a monolithic application is only shifted into the network, but still persists.
--


== So, you invest time/resources into benchmarking your application only to find that a t2.nano/t2.micro is too big for a single microservice!

[NOTE.speaker]
--
Determining the ideal instance size for your application is a challenge in any environment, not just in a microservices one, so you'll almost always be over-provisioning your compute.
--


== And you can't go down, so you trade utilisation for HA!


== Look for the bare necessities...

1 region +
~3 envs (dev, qa & prod) +
>1 AZ (for HA) +
>= 1 ec2 per AZ (min 2)

[NOTE.speaker]
--
Let's pretend you've got 3 environments and to maintain some sort of HA, you need at least 1 EC2 instance in at least 2 AZs per environment.

The reality is, most of us are in 3 AZs and multiple regions (particularly in production), but let's use this as an example.
--


== Les' Law 

{empty} +

*_m = e * az * opec2_*

{empty} +

[.smallprint]
And for those who can't do the maths...

[.smallprint]
3 environments (_e_) x 2 availability zones (_az_) x 1 over-provisioned EC2 instances (_opec2_) = 6 over-provisioned EC2 instances per microservice (_m_)

[NOTE.speaker]
--
Even when the service is not running under full load (highly likely in dev and qa), we're using 6 over-provisioned EC2 instances to run just 1 microservice.
--


== But it doesn't stop there, because...

[.fragment]
You also have 1x CLB per microservice, per environment^*^!

[.fragment]
[.smallprint]#^*^Id est, you're running multiple CLBs because you are hosting multiple applications (e.g. www.example.com, shop.example.com, unicorns.examples.com, etc.).#


== Actually I lied...

This isn't my equation; someone at Amazon worked this out a long time ago, which (if you think back a few slides) is why Amazon is the world's third largest technology company based on revenue.


== So, what is ECS?

Amazon EC2 Container Service (ECS) is a highly scalable, high performance container management platform that supports Docker containers and allows you to easily run applications on a managed cluster of EC2 instances.

https://aws.amazon.com/about-aws/whats-new/2015/04/amazon-ec2-container-service-is-now-generally-available/[GA on 2015-04-09].


== You can use ECS to schedule the placement of containers across your EC2 instances based on your resource needs, isolation policies and availability requirements, so you can *start driving up your utilisation without sacrificing availability!*


== ECS is elastic, so it allows you to grow from a single container on a single instance to thousands of containers across hundreds of instances, hopefully without adding too much additional complexity.


== ECS eliminates the need for you to install, operate and scale your own cluster management infrastructure (e.g. Kubernetes, Mesos, DC/OS, Swarm, etc.).


== And because it's on AWS, you have access to all the other AWS services that you're already familiar with (e.g. EC2, VPC, ELBs, EBS, EFS, S3, security groups, IAM, CloudWatch, CloudTrail, X-Ray, etc.).


== You can also integrate your own/third-party schedulers to meet your specific business/application requirements.


== But best of all, *there's no additional charge for ECS*; you only pay for the AWS resources (e.g. EC2 instances, EBS volumes, ELbs, etc.) you use (and hopefully you'll be using a lot less as a result).


== A brief look at Beanstalk

Alternatively, you could look at Elastic Beanstalk (a PaaS layer over ECS) to rapidly deploy Docker containers on AWS; however, using ECS directly gives you more fine-grained control and access to a much wider set of use cases.


== ECS key concepts/components

* EC2 Container Registry (ECR)
* ECS Container Instance
* ECS Cluster
* ECS Task Definition
* ECS Task
* ECS Service
* ECS Scheduler


== EC2 Container Registry (ECR)

*ECR is a AWS managed Docker registry similar to https://hub.docker.com/[Docker Hub].*

* ECR supports private Docker repositories with resource-based permissions using IAM, so only specific users/instances can access repositories/images.
* Developers can use the standard Docker CLI to push, pull and manage images. 
* ECR storage costs $0.10GB/m and data transfer out (`docker pull`) costs $0.090GB/m for the first 10TB.
* Data transfer in (`docker push`) is free.


== ECS Container Instance

*An ECS Container Instance is just an EC2 instance running the Docker daemon and the Amazon ECS container agent.*

* The Amazon ECS container agent allows container instances to connect to your ECS cluster.
* The source code for Amazon's ECS container agent is available on https://github.com/aws/amazon-ecs-agent[GitHub] under Apache License, Version 2.0 and Amazon encourages PRs. Yay!
* The ECS container agent is included in Amazon's https://aws.amazon.com/marketplace/pp/B00U6QTYI2[ECS-Optimized Amazon Linux AMI] (Amazon EULA), but you can also install it on any EC2 instance that meets the http://docs.aws.amazon.com/AmazonECS/latest/developerguide/container_instance_AMIs.html[minimum requirements].
* Just like a regular EC2 instance (because that's what it is), you can register your ECS container instances with an ASG within a VPC, attach EBS volumes and configure them to send logs to CloudWatch Logs, etc.

[NOTE.speaker]
--
The https://www.apache.org/licenses/LICENSE-2.0[Apache License, Version 2.0] is a free software license, compatible with the https://www.gnu.org/licenses/gpl-3.0.en.html[GNU General Public License, Version 3.0].
--


== ECS Cluster

*An ECS Cluster is just a logical group of EC2 instances (an EC2 resource pool) that you can place containers (a.k.a. tasks) on.*

* When you first use ECS, a default cluster is created for you, but you can create multiple clusters in an account to keep your resources separate. 
* ECS clusters can contain multiple different EC2 instance sizes and types (on-demand, reserved, spot).
* ECS clusters are region-specific.
* ECS container instances can only be a part of one ECS cluster at a time.
* You can create custom IAM policies for your ECS clusters to allow or restrict users.


== ECS Task Definition

*A ECS Task Definition describes the configuration of a single container or group of containers (e.g. which Docker image to use, what data volumes to attach and any ports to expose, etc.), similar to a `docker-compose.yml`.*

Some of the things you can configure in a task definition include:
* Docker image(s) to use.
* CPU and memory allocation per container.
* Containers links.
* Docker networking mode.
* Port mappings (from the container to the host instance), if any.
* The command the container should run when started, including any environment variables.
* Any data volumes to mount.
* IAM role to use.
* Essential flag.

[NOTE.speaker]
--
Your entire application stack does not need to exist in a single task definition and in most cases probably shouldn't.
--


== Example Task Definition

[source,json]
----
{
      "family": "web-timer",
      "containerDefinitions": [
      {
              "name": "web",
              "image": "nginx",
              "cpu": 99,
              "memory": 100,
              "portMappings": [{
                      "containerPort": 80,
                      "hostPort": 80
              }],
              "essential": true,
              "mountPoints": [{
                      "sourceVolume": "webdata",
                      "containerPath": "/usr/share/nginx/html",
                      "readOnly": true
              }]
      }, {
              "name": "timer",
              "image": "busybox",
              "cpu": 10,
              "memory": 20,
              "entryPoint": ["sh", "-c"],
              "command": ["while true; do date > /nginx/index.html; sleep 1; done"],
              "mountPoints": [{
                      "sourceVolume": "webdata",
                      "containerPath": "/nginx/"
              }]
      }],
      "volumes": [{
              "name": "webdata",
              "host": {
                      "sourcePath": "/ecs/webdata"
              }}
      ]
}
----

[.smallprint]
Courtesy of http://docs.aws.amazon.com/cli/latest/reference/ecs/register-task-definition.html[AWS CLI Command Reference]


[NOTE.speaker]
--
`family` corresponds to the task definition name.

`cpu` is the number of CPU units to reserve for the container.
An ECS container instance has 1,024 CPU units for every CPU core (1024/100=10.24 rounded down because the CPU units field only supports integers).

Hard and soft limits correspond to the `memory` and `memoryReservation` respectively.
If you specify a hard limit (`memory`), your container will be killed if it attempts to exceed that limit.
If you specify a soft limit (`memoryReservation`), ECS reserves that amount of memory for your container; however, the container can request up to the hard limit (if specified) or all of the available memory on the container instance, whichever is reached first.
If you specify both, the hard limit must be greater than the soft limit.

If `essential` is set to true, any failure of that container will stop the task.

Each time you update a task definition (e.g. to update the image tag/version), a new revision of the task definition is created to allow for easy rollback.

We'll come onto why this is a bad example later, but for those who can't wait...
If you use an ALB, you can set the `hostPort` to `0` to enable dynamic host port mapping, which allows you to run more than one copy of a task on a single ECS container instance!!!
--


== ECS Task

*A Task is the running state of a task definition.*

* When a task runs, the underlying container(s) start and when all the container processes end, the task ends.
* Tasks can either be short-lived (i.e. batch jobs) or long-lived _services_ (i.e. web apps).
* All the containers comprising the same task run on the same EC2 instance.


== ECS Service

*A service launches and maintains a desired count of copies of your task definition on your cluster.*

* If any task in your service stops/failed/is killed, the service scheduler will launch another instance of your task definition to replace it.
* By default, the service scheduler spreads tasks across AZs, but you can use task placement strategies and constraints to customise task placement decisions.
* Optional deployment configuration (min/max healthy percent) controls how many tasks run during the deployment and the ordering of stopping and starting tasks. 
* The ECS Services scheduler can optionally register tasks with an ELB.

[NOTE.speaker]
--
A deployment is triggered by either updating the task definition or desired count of a service.
--


== ECS Schedulers

*A scheduler handles the logic of running tasks/containers on a cluster.*

Current scheduler options include:

* Service scheduler, good for long-running tasks and applications (e.g. web servers).
* Manually running tasks, good for batch jobs or one-off tasks (e.g. queue work).
* You can also run tasks on a cron(8) schedule, via CloudWatch Events rules, for reoccurring batch jobs (e.g. backups).
* Other third-party/custom schedulers, such as https://github.com/blox/blox[Blox] (Apache-2.0), for extra flexibility/control.

Both the `RunTask` and `CreateService` actions allow you to specify task placement constraints (e.g. never run these 2 tasks on the same instance), and task placement strategies (i.e. binpack, random, spread) to customise how the ECS scheduler places your tasks.

[NOTE.speaker]
--
If you would like tasks to run at set intervals, you can create a CloudWatch Events rule to run one or more tasks at either a specific interval (every _n_ minutes/hours/days) or you can use ccrontab(5) expressions.

Blox is an free/libre, open source project that gives you more control over how your containers run on ECS.

To make appropriate placement decisions and start/stop containers, etc., custom schedulers leverage the same cluster state information and StartTask API operations available to any AWS customer via the ECS API, so it is entirely feasible for you to write your own ECS scheduler.

By default, ECS supports the following task placement strategies:
* `binpack`: Place tasks based on the least available amount of CPU or memory. This minimizes the number of instances in use.
* `spread`: Place tasks evenly based on the specified value. Accepted values are attribute key:value pairs, instanceId, or host.
* `random`: Place tasks randomly.
--


== A quick recap

* ECR =~ Docker Hub on AWS
* Container Instance =~ EC2 Instance + Docker daemon + ECS Agent daemon
* Cluster =~ EC2 resource pool
* Task Definition =~ Description of work
* Task =~ The actual work
* Service =~ Manager of indefinite workloads
* Scheduler =~ Scheduler of the work


== But, there's an elephant in the room...

[.fragment]
The Classic Elastic Load Balancer (CLB) from AWS' minestrone soup (EC2-Classic network) days.

[NOTE.speaker]
--
So, we've talked about whales, now it's time to talk about elephants.

If you really want to drive up utilisation across your (reserved) EC2 instances then there's an elephant in the room, the Classic ELB.
--

== The holy trinity of ELB

. Original ELB, renamed to Classic Load Balancer (CLB)
. Application Load Balancer (ALB)
. Network Load Balancer (NLB)

[NOTE.speaker]
--
It's important to understand that ELBs are not magic, they're just special EC2 instances running a bastardised HAProxy (I'm guessing) connected to the EC2 control plane.
They live inside AWS' ELB VPC (with subnets in each AZ, just like your VPCs), which sits alongside customer VPCs, which they have the ability to inject traffic into.
Thus the ELB team is also a demanding _"customer"_ of the EC2 team, just like you.

All ELBs always use multiple AZs, so even if you're only in one AZ, ELBs will still route traffic though the other AZs, so if AWS loose an AZ, traffic will still get to your box and all requests will be automatically shifted to healthy AZs via Route53.

Also worth a mention, Amazon Certificate Manager (ACM) issues free TLS/SSL certificates, with free automatic renewal, which you can easily associate with your ELBs.
--


==  Classic Load Balancer (CLB)

GA:: https://aws.amazon.com/releasenotes/Amazon-EC2/2528[2009-05-17]
Protocols:: TCP/SSL (connections level, layer 4) and limited HTTP/HTTPS (request level, layer 7)
Networks:: EC2-Classic and EC2-VPC
Health Checks/CloudWatch Metrics:: Limited

[NOTE.speaker]
--
There are really two different types of load balancers, layer 4 (network) and layer 7 (application).

Layer 4 (network) is connection-based (TCP/SSL) load balancing, simply forwarding packets to the backends without looking at them.
Incoming client connections are bound to the server, so every time a new request comes in it is bound to a particular backend instance and will never move.
There's no header modification, because they're just blindly passing packets through to the backends, which means no `X-Forwarded-For` header, because they're not actually do anything with the request.
So, if you want to know the source IP of the client that's connecting to you there's a feature called https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt[Proxy Protocol], which comes from the HAProxy world, that prepends source and destination IP and ports to requests, thus allowing you to forward the source IP through to the destination.

Layer 7 (application) loads balancers speak HTTP and HTTPS.
For every request that comes in they wait for all the packets to arrive, reassemble the HTTP request, inspect/modify headers, etc., before forwarding it on.
Here we're doing a lot more work on the load balancer and connections are actually terminated on the load balancer, which have a connection pool open to the backend instances (so you'll see them open up multiple connections to your backends) which they use to forward on the HTTP requests.
At layer 7, headers can be modified (e.g. inserting an `X-Forwarded-For` header with the source IP of the original requester, etc.).
--


== CLBs have some drawbacks...


== You can only register 1 port per instance!

If you tried to register the same instance again with a different port, CLB would say, _"no, that instance ID is already registered, go away!"_

Which basically means a 1:1 between service and instance.

[NOTE.speaker]
--
So with CLBs you register an instance via the API, but when you did you can only provide 1 port for that instance and then you were done for that instance.
If you tried to register the same instance again, CLBs would tell you to get lost, which meant a 1:1 container per EC2 instance with CLBs.
Very wasteful/expensive.
--


== No dynamic port mappings!

Therefore with CLB, your task definition contains static port mappings (container port to host port), so the number of container instances you launch must be >= the number of tasks!

[NOTE.speaker]
--
Which meant *you* had to manage and keep track of all the ports your services listen on (e.g. on a wiki page), because not all containers can listen on 80 because there's only one port 80 on a box.
But you don't want control over what ports your containers listen on, ideally containers will all use a dynamic ephemeral port and your load balancer will automagically discover and use them.
--


== Enter the Application Load Balancer

GA:: https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/[2016-08-11]
Protocols:: HTTP and HTTPS (request level, layer 7)
Networks:: EC2-VPC only
Health Checks/CloudWatch Metrics:: Improved
Killer Features:: Path/Header-based routing (multiple applications behind a single ALB), dynamic port mapping/service discovery, IPv6, HTTP/2, WebSockets, WAF (layer 7 firewall), X-Ray (`X-Amzn-Trace-ID` header), termination protection and improved performance (valuable for real-time/streaming applications).

[NOTE.speaker]
--
HTTP/2 and WebSockets are on by default, no additional configuration necessary, if an ALB sees a HTTP/2 or WebSockets request it will automatically upgrade the connection.

AWS Website Application Firewall, is a layer 7 firewall with default rule support for SQL-injection, cross-site scripting, bad-actor IPs, bad bots and HTTP flood attacks, etc.

ALB adds support for request tracing by adding a unique ID to every request that goes through the ALB (e.g. `X-Amzn-Trace-ID`, which gets pumped into X-Ray).

Termination protection is a feature that was sorely missing from the original ELBs.
AWS even developed an internal API function named `undeleteCustomerELB`.
Haha!

ALBs are much more performant than CLBs, so it might be worth switching and future-proofing yourself even if you don't need all the extra features just yet.
If you were doing very large downloads or streaming the old CLB would do quite a lot of buffering and thats not great, ALB solves this problem.

With ALB the is no additional bandwidth charge for cross-zone traffic.

With CLBs you had the option to use different versions of the managed cypher polices as well as define your own; whereas with ALbs, Amazon only offer managed policies following industry best practices, so you're always up-to-date.

Note, ALB breaks ELB API compatibility (the original API was far too simple) and introduces a bunch of new abstractions/resource types (listener rules, target groups, targets).
--


== There's also Network Load Balancers (NLBs), but we're...

.Courtesy of http://www.mgm.com/[Metro-Goldwyn-Mayer Studios Inc.]
image::README/out-of-time.jpg[Out of Time (2003),,800]


== Bascially, ALBs are layer 7 and NLBs are layer 4

[NOTE.speaker]
--
Spotted the problem yet?
You're going to need two ELBs, 1x ALB and 1x NLB to host applications, like Jenkins, which need an ALB for the web UI (8080/HTTP) and an NLB for the AJP connector (8009/AJP13).
--


== ALB key concepts/components

* Load Balancer
* Listener
* Listener Rules
* Target Groups
* Targets
* Health Checks

[NOTE.speaker]
--
Back to ALBs.
--


== Load Balancer

*A load balancer serves as the single point of contact for HTTP/HTTPS clients, it's where you point your CNAMEs.*

* You add one or more listeners to your load balancer.
* An ALB can also forward to a CLB, which is pretty neat.


== Listener

*Listeners define the port and protocol on which the load balancer listens for incoming connections from clients and forwards them to one or more target groups, based on listener rules.*

* Each ALB needs at least 1 listener to accept incoming traffic.
* ALBs support up to 50 isteners per load balancer.


== Listener Rules

*Listener rules (i.e. path-based/header-based routing rules) provide a link between listeners and target groups and consist of conditions, actions and priorities.*

* When a request arrives, the listener inspects the condition (e.g. `GET /foo/ HTTP/1.1` or `Foo: bar`), runs through all the rules, finds the first one that matches and apples the action, i.e. forward the request to a target in the the specified target group (e.g. `foo`).
* Listener rules are evaluated in priority order and a target (from the specified target group) is selected via round robin.
* You must define a default (catchall) rule for each listener, if you don't the ALB will return a 503.
* ALBs support up to 100 rules per load balancer (not counting default rules).

[NOTE.speaker]
--
If a request doesn't match any of the rules then it will fall through to the default rule; therefore, you can emulate a CLB with just a default rule and a single target group.

So as well as path-based routing you can also set different headers (e.g. API versions, etc.) to route requests to different targets.
--


== Target Groups

*Target groups are a logical grouping of EC2/ECS container instances behind a load balancer (i.e. the logical grouping of backends).*

* They exist independently from load balancers.
* Targets groups are a regional construct that can be associated with an ASG (different applications that might scale differently).
* Typically target group boundaries usually map to application boundaries.
* You can have >1000 targets per target group.


[NOTE.speaker]
--
Auto-scaling now supports scaling at the target group level, which makes sense given that target groups maps to different applications.
CloudWatch metrics are provided at the global load balancer and target group level.
--


== Targets

*Targets are logical load balancer targets (e.g. EC2 instance, microservice, container).*

* Multiple targets can be registered with the same target group (on different ports).
* A single target can with registered with multiple target groups.
* ALBs support up to 1000 targets per load balancer.
* Targets can be on-prem, the only constraint they have to use an RFC 1918 (IPv4) or RFC 4193 (IPv6) address (i.e. VPC peering, DirectConnect, VPN, etc.).

[NOTE.speaker]
--
So, if you have an instance running multiple applications there's nothing stopping you registering that instance with multiple target groups, but be careful it's a lot of rope!
--


== Health Checks

*Health checks, defined on the target group, check the health of your application.*

* The load balancer routes requests to the registered targets that are healthy and shifts traffic away from impaired ones.
* An ASG can also respond to health checks and replace any unhealthy instances.
* Unlike CLB health checks, you can now pass a list of successful HTTP response codes (not just 200) and ALBs fail open (instead of returning a 503) if all health checks fail.
* You also get detailed reasons for health check failures (i.e. timeouts, connection errors, 500s, etc.), again something you didn't get with CLBs.

[NOTE.speaker]
--
Surge queues (from CLBs) are generally a bad thing; thankfully they are gone, replaced with the rejected connection count metric.
--

== Putting it all together


== !

.Courtesy of https://aws.amazon.com/blogs/compute/microservice-delivery-with-amazon-ecs-and-application-load-balancers/[Amazon Web Services, Inc.]
image::README/alb.png[ALB Diagram,,800]

[NOTE.speaker]
--
Here each listener contains a default rule and one listener contains another rule that routes requests to a different target group
One target is registered with two target groups. 
--


== !

.Courtesy of http://www.allthingsdistributed.com/2015/07/under-the-hood-of-the-amazon-ec2-container-service.html[Werner Vogels, C.T.O. and V.P. of Amazon.com]
image::README/ecs.png[ECS Diagram,,800]


== Multiple (identical) containers on the same instance

* Unlike with CLBs, when you register an EC2 instance with an ALB, you provide both the instance-id *and* the port (which makes up a composite key), so long as the port is different, you can keep registering the same instance over and over.^*^
* Which means (thanks to dynamic port mappings and basic service discovery) multiple instances of the same task can run on the same instance.
* Therefore, you can carve up a single EC2 instance into smaller and smaller chunks and really drive up the utilisation.
* Which also means, you don't have to worry too much about finding the prefect instance size.

[.smallprint]
^*^The current limit is 1,000 targets per load balancer, but possibly up to ~65,000, if you ask AWS nicely.


== Multiple applications behind the same load balancer

* Thanks to their path/header-based routing, ALBs allow you to host multiple applications behind a single load balancer, so you can drop down to one load balancer and reduce your hourly (and operational) costs^*^.
* That's a huge cost saving if you're currently running multiple CLBs, because you are hosting multiple applications.

[.smallprint]
^*^Obviously your bandwidth costs will remain the same, assuming your severing the same amount of traffic.


== ECS + ALB 

* If you combine ALB with ECS, ECS will automatically register tasks with an ALB using dynamic ports (just set `hostPort` to `0` in your task definition).
* This is not just supported by ECS, if you're only running a few services on a single box, so long as their listening on different ports, you can register the same instance multiple times with an ALB.
* Therefore, you can mix and match between EC2 instances and containers (i.e. ECS tasks) as you migrate/move/redevelop your application/infrastructure.


== Remember Les' Law (where we traded utilisation for HA)?

*_m = e * az * opec2_*

[.smallprint]
3 environments (_e_) x 2 availability zones (_az_) x 1 over-provisioned EC2 instances (_opec2_) = 6 over-provisioned EC2 instances per microservice (_m_)

With ECS + ALB you you can run 2, 5, 10 or 100 different microservices or copies of the same microservice on the same 6 EC2 instances; whereas previously with EC2 + ELB you had wasted capacity and increased overheads because a t2-micro was too large for your microservice and you needed an ELB for each of them.

[NOTE.speaker]
--
Now if you consider full production environments spread across multiple regions and savings can be pretty tremendous.
--


== A couple of notes of caution


== Consider your blast radius when grouping applications on a single ECS cluster behind a single ALB.


== If you do your homework and get all of this right you should always be running at full capacity, so you might starting seeing errors at your quietest times if you've taken out too much capacity.


== ECS has a few known limitations

* CloudWatch's standard 5 minute intervals is not really quick enough to react to scaling events (you need see what's going on at a more granular level), so you *have* to pay for enhanced metrics, if you're not already.
* Lack of container-level monitoring, plus the usual CloudWatch limitations you're all familiar with.
* It's not easy to tell at a glance all the containers running on an instance.

[.smallprint]
We're currently using https://prometheus.io/[Prometheus] (Apache-2.0) to help with some of this.


== Want to get started?

Try the ECS first run wizard at https://console.aws.amazon.com/ecs/home#/firstRun, just be aware of the AWS costs incurred as a result.


== And finally, very briefly, ECS vs. Kubernetes^*^

[.smallprint]
^*^From the point of view of someone without any production K8s experience.

[NOTE.speaker]
--
Microsoft are here at the Docker Meetup trying to sell you Kubernetes on Azure, so here's a very brief look at ECS vs. Kubernetes from the point of view of someone without any production K8s experience.
--


== ECS

* Easy to grok.
* Operational simplicity.
* If you can `docker run`, generally you're good to go on ECS (just give your cluster a name and you start loading up your EC2 instances with containers).
* Familiar AWS environment (mostly).
* Lots of people already use AWS.
* Doesn't try to solve all your problems.


== K8s

* Brilliantly engineered, but quite heady.
* A much bigger platform with a lot of extra constructs/abstractions.
* Substantial ops burden when running outside of GCE (and Azure?).
* Tries to solve all your problems (e.g. deployment model, monitoring, logging, etc. are all easier problems on K8s).

[NOTE.speaker]
--
Kubernetes is seeing a lot of the same hype Docker was seeings a few years back, i.e. if you run Kubernetes all your deployment/CD problems will solved, which is not the case.
--


== Roll credits (in order of appearance)

[.credits]
* https://en.wikipedia.org/wiki/Blue_whale
* http://www.nationalgeographic.com/animals/mammals/b/blue-whale/
* Schlesinger, W. H., Holland, H. D. & Turekian, K. K., _Biogeochemistry_, Volume 8 (Elsevier, 2005)
* https://blog.education.nationalgeographic.com/2015/08/31/how-big-is-a-blue-whales-heart/
* https://en.wikipedia.org/wiki/MDMA
* https://www.docker.com/
* https://github.com/moby
* https://blog.docker.com/2015/05/dockers-2nd-birthday-by-the-numbers/
* https://blog.docker.com/2015/02/docker-project-announces-open-source-a-thon-to-support-whale-and-marine-wildlife-conservation/
* http://www.oceanicsociety.org/
* Schmidt, K., _High Availability and Disaster Recovery: Concepts, Design, Implementation_ (Springer-Verlag, 2006)
* http://dockerdocs.org/what-is-docker/
* http://fortune.com/global500
* https://en.wikipedia.org/wiki/List_of_the_largest_information_technology_companies
* https://en.wikipedia.org/wiki/List_of_Amazon.com_products_and_services
* https://martinfowler.com/articles/microservices.html
* http://arnon.me/2014/03/services-microservices-nanoservices/
* http://www.codingthearchitecture.com/2014/05/01/where_is_the_complexity.html
* https://aws.amazon.com/about-aws/whats-new/2015/04/amazon-ec2-container-service-is-now-generally-available/
* https://aws.amazon.com/ecs/pricing/
* https://aws.amazon.com/elasticbeanstalk/
* http://docs.aws.amazon.com/AmazonECS/latest/developerguide/
* https://aws.amazon.com/ecr/pricing/
* https://hub.docker.com/
* https://github.com/aws/amazon-ecs-agent
* https://aws.amazon.com/marketplace/pp/B00U6QTYI2
* http://docs.aws.amazon.com/AmazonECS/latest/developerguide/container_instance_AMIs.html
* http://docs.aws.amazon.com/cli/latest/reference/ecs/register-task-definition.html
* https://github.com/blox/blox
* https://aws.amazon.com/releasenotes/Amazon-EC2/2528
* https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/
* http://www.mgm.com/
* http://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-limits.html
* https://aws.amazon.com/blogs/compute/microservice-delivery-with-amazon-ecs-and-application-load-balancers/
* http://www.allthingsdistributed.com/2015/07/under-the-hood-of-the-amazon-ec2-container-service.html
* https://docs.aws.amazon.com/elasticloadbalancing/latest/application/
* https://docs.aws.amazon.com/elasticloadbalancing/latest/network/
* https://aws.amazon.com/blogs/compute/bluegreen-deployments-with-amazon-ecs/
* https://github.com/awslabs/ecs-blue-green-deployment
* https://prometheus.io/
* https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/
* https://console.aws.amazon.com/ecs/home#/firstRun

[.smallprint]
There are a lot of good materials out there; https://duckduckgo.com/[DDG] is your friend!

[NOTE.speaker]
--
List of references/sources in order of appearance.
--


== Thank you for listening!

Q&A + Demo^*^ 

[.smallprint]
^*^Time permitting.

[NOTE.speaker]
--
We only scratched the surface here and obviously there's a lot more detail we could have gone onto had this talk been scheduled for a day (or a week), instead of an hour.

WARNING: With regards to the demo, attempting to push the base https://hub.docker.com/_/golang/[golang image] to a fresh ECR repository may take an awful long time.
--
